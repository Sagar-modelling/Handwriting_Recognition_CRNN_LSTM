{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Reshape, Bidirectional, LSTM, Dense, Lambda, Activation, BatchNormalization, Dropout\nfrom keras.optimizers import Adam","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-08-04T14:14:23.040266Z","iopub.execute_input":"2021-08-04T14:14:23.040626Z","iopub.status.idle":"2021-08-04T14:14:23.048334Z","shell.execute_reply.started":"2021-08-04T14:14:23.040594Z","shell.execute_reply":"2021-08-04T14:14:23.047448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_train_v2.csv')\nvalid = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_validation_v2.csv')\ntrain","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:37:58.009073Z","iopub.execute_input":"2021-08-04T12:37:58.009397Z","iopub.status.idle":"2021-08-04T12:37:58.507038Z","shell.execute_reply.started":"2021-08-04T12:37:58.009369Z","shell.execute_reply":"2021-08-04T12:37:58.506087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(15, 10))\n\nfor i in range(9):\n    ax = plt.subplot(3,3,i+1)\n    img_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+train.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(train.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:38:01.224234Z","iopub.execute_input":"2021-08-04T12:38:01.224608Z","iopub.status.idle":"2021-08-04T12:38:01.980643Z","shell.execute_reply.started":"2021-08-04T12:38:01.224579Z","shell.execute_reply":"2021-08-04T12:38:01.979536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cleaning Data","metadata":{}},{"cell_type":"code","source":"print(\"Number of NaNs in train set      : \", train['IDENTITY'].isnull().sum())\nprint(\"Number of NaNs in validation set : \", valid['IDENTITY'].isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:38:07.369157Z","iopub.execute_input":"2021-08-04T12:38:07.369477Z","iopub.status.idle":"2021-08-04T12:38:07.412585Z","shell.execute_reply.started":"2021-08-04T12:38:07.369449Z","shell.execute_reply":"2021-08-04T12:38:07.411845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dropna(axis=0, inplace=True)#axis =0, removing rows otherwisw axis =1. removing columns\nvalid.dropna(axis=0, inplace=True) #true means dropping","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:38:10.504125Z","iopub.execute_input":"2021-08-04T12:38:10.504481Z","iopub.status.idle":"2021-08-04T12:38:10.614872Z","shell.execute_reply.started":"2021-08-04T12:38:10.504452Z","shell.execute_reply":"2021-08-04T12:38:10.614145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Also, there are some images in our data with the label 'UNREADABLE'. Lets check those images and remove them.","metadata":{}},{"cell_type":"code","source":"unreadable = train[train['IDENTITY'] == 'UNREADABLE']\nunreadable.reset_index(inplace = True, drop=True)\n\nplt.figure(figsize=(15, 10))\n\nfor i in range(9):\n    ax = plt.subplot(3, 3, i+1)\n    img_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+unreadable.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap = 'gray')\n    plt.title(unreadable.loc[i, 'IDENTITY'], fontsize=12)\n    plt.axis('off')\n\nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:38:12.579433Z","iopub.execute_input":"2021-08-04T12:38:12.579821Z","iopub.status.idle":"2021-08-04T12:38:13.220537Z","shell.execute_reply.started":"2021-08-04T12:38:12.57979Z","shell.execute_reply":"2021-08-04T12:38:13.219695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[train['IDENTITY'] != 'UNREADABLE']\nvalid = valid[valid['IDENTITY'] != 'UNREADABLE']\nvalid","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:38:16.32956Z","iopub.execute_input":"2021-08-04T12:38:16.329904Z","iopub.status.idle":"2021-08-04T12:38:16.404195Z","shell.execute_reply.started":"2021-08-04T12:38:16.329872Z","shell.execute_reply":"2021-08-04T12:38:16.403314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some labels which are in lowercase. To maintain uniformity in the labels, I convert all the labels to uppercase.","metadata":{}},{"cell_type":"code","source":"train['IDENTITY'] = train['IDENTITY'].str.upper()\nvalid['IDENTITY'] = valid['IDENTITY'].str.upper()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:38:19.869687Z","iopub.execute_input":"2021-08-04T12:38:19.870035Z","iopub.status.idle":"2021-08-04T12:38:20.084768Z","shell.execute_reply.started":"2021-08-04T12:38:19.870002Z","shell.execute_reply":"2021-08-04T12:38:20.083781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reset the index and we are done with cleaning. ","metadata":{}},{"cell_type":"code","source":"train.reset_index(inplace = True, drop=True) \nvalid.reset_index(inplace = True, drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:38:22.659119Z","iopub.execute_input":"2021-08-04T12:38:22.659466Z","iopub.status.idle":"2021-08-04T12:38:22.66587Z","shell.execute_reply.started":"2021-08-04T12:38:22.659435Z","shell.execute_reply":"2021-08-04T12:38:22.663119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing and preparing the images for training","metadata":{}},{"cell_type":"markdown","source":"* The images are loaded as grayscale and reshaped to width 256 and height 64.  \n* The width and height are cropped if they are greater than 256 and 64 respectively. If they are smaller, then the image is padded with white pixels. Finally the image is rotated clockwise to bring the image shape to (x, y). \n* The image is then normalized to range [0, 1]","metadata":{}},{"cell_type":"code","source":"def preprocess(img):\n    (h, w) = img.shape\n    \n    final_img = np.ones([64, 256])*255 # black white image\n    \n    # crop\n    if w > 256:\n        img = img[:, :256]\n        \n    if h > 64:\n        img = img[:64, :]\n    \n    \n    final_img[:h, :w] = img\n    return cv2.rotate(final_img, cv2.ROTATE_90_CLOCKWISE)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:38:25.73469Z","iopub.execute_input":"2021-08-04T12:38:25.735049Z","iopub.status.idle":"2021-08-04T12:38:25.743007Z","shell.execute_reply.started":"2021-08-04T12:38:25.735017Z","shell.execute_reply":"2021-08-04T12:38:25.741731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model will be trained on 30000 images and validate on 3000 images","metadata":{}},{"cell_type":"code","source":"train_size = 30000\nvalid_size= 3000","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:38:28.53919Z","iopub.execute_input":"2021-08-04T12:38:28.539537Z","iopub.status.idle":"2021-08-04T12:38:28.544068Z","shell.execute_reply.started":"2021-08-04T12:38:28.539506Z","shell.execute_reply":"2021-08-04T12:38:28.543159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = []\n\nfor i in range(train_size):\n    img_dir = '/kaggle/input/handwriting-recognition/train_v2/train/'+train.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = preprocess(image)\n    image = image/255\n    train_x.append(image)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:38:30.850486Z","iopub.execute_input":"2021-08-04T12:38:30.850798Z","iopub.status.idle":"2021-08-04T12:41:47.665446Z","shell.execute_reply.started":"2021-08-04T12:38:30.850768Z","shell.execute_reply":"2021-08-04T12:41:47.664648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_x = []\n\nfor i in range(valid_size):\n    img_dir = '/kaggle/input/handwriting-recognition/validation_v2/validation/'+valid.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    image = preprocess(image)\n    image = image/255\n    valid_x.append(image)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:41:50.451191Z","iopub.execute_input":"2021-08-04T12:41:50.451518Z","iopub.status.idle":"2021-08-04T12:42:10.6485Z","shell.execute_reply.started":"2021-08-04T12:41:50.451488Z","shell.execute_reply":"2021-08-04T12:42:10.647743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = np.array(train_x).reshape(-1, 256, 64, 1)#array will get reshaped in such a way that the resulting array has only 1 column\nvalid_x = np.array(valid_x).reshape(-1, 256, 64, 1) #(16384,1)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:42:13.936194Z","iopub.execute_input":"2021-08-04T12:42:13.936512Z","iopub.status.idle":"2021-08-04T12:42:15.255252Z","shell.execute_reply.started":"2021-08-04T12:42:13.936481Z","shell.execute_reply":"2021-08-04T12:42:15.254198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preparing the labels for CTC Loss\n\nLearn more about CTC loss and why its amazing for text recognition from [here](https://theailearner.com/2019/05/29/connectionist-temporal-classificationctc/).\n\nThe labels have to be converted to numbers which represent each character in the training set. The 'alphabets' consist of A-Z and three special characters (-  '  and space). ","metadata":{}},{"cell_type":"code","source":"alphabets = u\"!\\\"#&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz \" \nmax_str_len = 24 # max length of input labels\nnum_of_characters = len(alphabets) + 1 # +1 for ctc pseudo blank(epsilon)\nnum_of_timestamps = 64 # max length of predicted labels\n\n\ndef label_to_num(label):\n    label_num = []\n    for ch in label:\n        label_num.append(alphabets.find(ch)) \n        #find() method returns the lowest index of the substring if it is found in given string otherwise -1\n        \n    return np.array(label_num)\n\ndef num_to_label(num):\n    ret = \"\"\n    for ch in num:\n        if ch == -1:  # CTC Blank\n            break\n        else:\n            ret+=alphabets[ch]\n    return ret","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:42:17.761222Z","iopub.execute_input":"2021-08-04T12:42:17.761553Z","iopub.status.idle":"2021-08-04T12:42:17.768519Z","shell.execute_reply.started":"2021-08-04T12:42:17.761523Z","shell.execute_reply":"2021-08-04T12:42:17.767518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name = 'JEBASTIN'\nprint(name, '\\n',label_to_num(name))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:42:21.441242Z","iopub.execute_input":"2021-08-04T12:42:21.441606Z","iopub.status.idle":"2021-08-04T12:42:21.447688Z","shell.execute_reply.started":"2021-08-04T12:42:21.441577Z","shell.execute_reply":"2021-08-04T12:42:21.446568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* **train_y** contains the true labels converted to numbers and padded with -1. The length of each label is equal to max_str_len. \n* **train_label_len** contains the length of each true label (without padding) \n* **train_input_len** contains the length of each predicted label. The length of all the predicted labels is constant i.e number of timestamps - 2.  \n* **train_output** is a dummy output for ctc loss. \n","metadata":{}},{"cell_type":"code","source":"train_y = np.ones([train_size, max_str_len]) * -1\ntrain_label_len = np.zeros([train_size, 1])\ntrain_input_len = np.ones([train_size, 1]) * (num_of_timestamps-2)\ntrain_output = np.zeros([train_size])\n\nfor i in range(train_size):\n    train_label_len[i] = len(train.loc[i, 'IDENTITY'])\n    train_y[i, 0:len(train.loc[i, 'IDENTITY'])]= label_to_num(train.loc[i, 'IDENTITY'])    ","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:42:24.406255Z","iopub.execute_input":"2021-08-04T12:42:24.406578Z","iopub.status.idle":"2021-08-04T12:42:25.812961Z","shell.execute_reply.started":"2021-08-04T12:42:24.40655Z","shell.execute_reply":"2021-08-04T12:42:25.811596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_y = np.ones([valid_size, max_str_len]) * -1\nvalid_label_len = np.zeros([valid_size, 1])\nvalid_input_len = np.ones([valid_size, 1]) * (num_of_timestamps-2)\nvalid_output = np.zeros([valid_size])\n\nfor i in range(valid_size):\n    valid_label_len[i] = len(valid.loc[i, 'IDENTITY'])\n    valid_y[i, 0:len(valid.loc[i, 'IDENTITY'])]= label_to_num(valid.loc[i, 'IDENTITY'])    ","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:42:28.316078Z","iopub.execute_input":"2021-08-04T12:42:28.316409Z","iopub.status.idle":"2021-08-04T12:42:28.47107Z","shell.execute_reply.started":"2021-08-04T12:42:28.316379Z","shell.execute_reply":"2021-08-04T12:42:28.470319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('True label : ',train.loc[100, 'IDENTITY'] , '\\ntrain_y : ',train_y[100],'\\ntrain_label_len : ',train_label_len[100], \n      '\\ntrain_input_len : ', train_input_len[100])","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:42:32.496032Z","iopub.execute_input":"2021-08-04T12:42:32.496368Z","iopub.status.idle":"2021-08-04T12:42:32.506718Z","shell.execute_reply.started":"2021-08-04T12:42:32.496338Z","shell.execute_reply":"2021-08-04T12:42:32.506095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Building our model\n","metadata":{}},{"cell_type":"code","source":"input_data = Input(shape=(256, 64, 1), name='input')\n\ninner = Conv2D(32, (3, 3), padding='same', name='conv1', kernel_initializer='he_normal')(input_data)  \ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max1')(inner)\n\ninner = Conv2D(64, (3, 3), padding='same', name='conv2', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(2, 2), name='max2')(inner)\ninner = Dropout(0.3)(inner)\n\ninner = Conv2D(128, (3, 3), padding='same', name='conv3', kernel_initializer='he_normal')(inner)\ninner = BatchNormalization()(inner)\ninner = Activation('relu')(inner)\ninner = MaxPooling2D(pool_size=(1, 2), name='max3')(inner)\ninner = Dropout(0.3)(inner)\n\n# CNN to RNN\ninner = Reshape(target_shape=((64, 1024)), name='reshape')(inner)\ninner = Dense(64, activation='relu', kernel_initializer='he_normal', name='dense1')(inner)\n\n## RNN\ninner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm1')(inner)\ninner = Bidirectional(LSTM(256, return_sequences=True), name = 'lstm2')(inner)\n\n## OUTPUT\ninner = Dense(num_of_characters, kernel_initializer='he_normal',name='dense2')(inner)\ny_pred = Activation('softmax', name='softmax')(inner)\n\nmodel = Model(inputs=input_data, outputs=y_pred)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:42:35.036344Z","iopub.execute_input":"2021-08-04T12:42:35.036673Z","iopub.status.idle":"2021-08-04T12:42:38.011934Z","shell.execute_reply.started":"2021-08-04T12:42:35.036644Z","shell.execute_reply":"2021-08-04T12:42:38.011075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The output shape of the predictions is (64, 30). The model predicts words of 64 characters and each character contains the probability of the 30 alphabets which we defined earlier.  ","metadata":{}},{"cell_type":"code","source":"# the ctc loss function\ndef ctc_lambda_func(args):\n    y_pred, labels, input_length, label_length = args\n    # the 2 is critical here since the first couple outputs of the RNN\n    # tend to be garbage\n    y_pred = y_pred[:, 2:, :]\n    return K.ctc_batch_cost(labels, y_pred, input_length, label_length)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:42:58.506564Z","iopub.execute_input":"2021-08-04T12:42:58.506885Z","iopub.status.idle":"2021-08-04T12:42:58.512259Z","shell.execute_reply.started":"2021-08-04T12:42:58.506856Z","shell.execute_reply":"2021-08-04T12:42:58.511169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = Input(name='gtruth_labels', shape=[max_str_len], dtype='float32')\ninput_length = Input(name='input_length', shape=[1], dtype='int64')\nlabel_length = Input(name='label_length', shape=[1], dtype='int64')\n\nctc_loss = Lambda(ctc_lambda_func, output_shape=(1,), name='ctc')([y_pred, labels, input_length, label_length])\nmodel_final = Model(inputs=[input_data, labels, input_length, label_length], outputs=ctc_loss)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:43:01.296408Z","iopub.execute_input":"2021-08-04T12:43:01.296765Z","iopub.status.idle":"2021-08-04T12:43:01.40693Z","shell.execute_reply.started":"2021-08-04T12:43:01.296732Z","shell.execute_reply":"2021-08-04T12:43:01.405923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the loss calculation occurs elsewhere, so we use a dummy lambda function for the loss\nfile_path_best = \"C_LSTM_best.hdf5\"\n\nmodel_final.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=Adam(lr = 0.0001))\n\ncheckpoint = ModelCheckpoint(filepath=file_path_best, \n                             monitor='val_loss', \n                             verbose=1, \n                             save_best_only=True, \n                             mode='min')\n\ncallbacks_list = [checkpoint]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:48:55.51725Z","iopub.execute_input":"2021-08-04T12:48:55.517606Z","iopub.status.idle":"2021-08-04T12:48:55.538717Z","shell.execute_reply.started":"2021-08-04T12:48:55.517575Z","shell.execute_reply":"2021-08-04T12:48:55.53761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train our model","metadata":{}},{"cell_type":"code","source":"history = model_final.fit(x=[train_x, train_y, train_input_len, train_label_len], y=train_output,validation_data=([valid_x, valid_y, valid_input_len, valid_label_len], valid_output),callbacks=callbacks_list,verbose=1,epochs=60, batch_size=128,shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T12:48:59.546313Z","iopub.execute_input":"2021-08-04T12:48:59.546677Z","iopub.status.idle":"2021-08-04T13:27:00.094562Z","shell.execute_reply.started":"2021-08-04T12:48:59.546649Z","shell.execute_reply":"2021-08-04T13:27:00.093503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-04T13:28:28.128257Z","iopub.execute_input":"2021-08-04T13:28:28.128626Z","iopub.status.idle":"2021-08-04T13:28:28.283037Z","shell.execute_reply.started":"2021-08-04T13:28:28.128592Z","shell.execute_reply":"2021-08-04T13:28:28.282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('/kaggle/working/C_LSTM_best.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T13:29:14.157606Z","iopub.execute_input":"2021-08-04T13:29:14.157928Z","iopub.status.idle":"2021-08-04T13:29:14.200171Z","shell.execute_reply.started":"2021-08-04T13:29:14.157899Z","shell.execute_reply":"2021-08-04T13:29:14.199434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Check model performance on validation set","metadata":{}},{"cell_type":"code","source":"preds = model.predict(valid_x)\ndecoded = K.get_value(K.ctc_decode(preds, input_length=np.ones(preds.shape[0])*preds.shape[1], \n                                   greedy=True)[0][0])\n\nprediction = []\nfor i in range(valid_size):\n    prediction.append(num_to_label(decoded[i]))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T13:29:18.01702Z","iopub.execute_input":"2021-08-04T13:29:18.017376Z","iopub.status.idle":"2021-08-04T13:29:20.857336Z","shell.execute_reply.started":"2021-08-04T13:29:18.017345Z","shell.execute_reply":"2021-08-04T13:29:20.856499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = valid.loc[0:valid_size, 'IDENTITY']\ncorrect_char = 0\ntotal_char = 0\ncorrect = 0\n\nfor i in range(valid_size):\n    pr = prediction[i]\n    tr = y_true[i]\n    total_char += len(tr)\n    \n    for j in range(min(len(tr), len(pr))):\n        if tr[j] == pr[j]:\n            correct_char += 1\n            \n    if pr == tr :\n        correct += 1 \n    \nprint('Correct characters predicted : %.2f%%' %(correct_char*100/total_char))\nprint('Correct words predicted      : %.2f%%' %(correct*100/valid_size))","metadata":{"execution":{"iopub.status.busy":"2021-08-04T13:29:24.106992Z","iopub.execute_input":"2021-08-04T13:29:24.107327Z","iopub.status.idle":"2021-08-04T13:29:24.143958Z","shell.execute_reply.started":"2021-08-04T13:29:24.107297Z","shell.execute_reply":"2021-08-04T13:29:24.143129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Some predictions on test set","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/handwriting-recognition/written_name_validation_v2.csv')\n\nplt.figure(figsize=(15, 10))\nfor i in range(16):\n    ax = plt.subplot(4, 4, i+1)\n    img_dir = '/kaggle/input/handwriting-recognition/validation_v2/validation/'+test.loc[i, 'FILENAME']\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap='gray')\n    \n    image = preprocess(image)\n    image = image/255.\n    pred = model.predict(image.reshape(1, 256, 64, 1))\n    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n                                       greedy=True)[0][0])\n    plt.title(num_to_label(decoded[0]), fontsize=12)\n    plt.axis('off')\n    \nplt.subplots_adjust(wspace=0.2, hspace=-0.8)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T13:56:23.866211Z","iopub.execute_input":"2021-08-04T13:56:23.866562Z","iopub.status.idle":"2021-08-04T13:56:25.300334Z","shell.execute_reply.started":"2021-08-04T13:56:23.866533Z","shell.execute_reply":"2021-08-04T13:56:25.299604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(1, 1))\nfor i in range(1):\n    ax = plt.subplot(1, 1, i+1)\n    img_dir = \"/kaggle/input/test123/tr.PNG\"\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap='gray')\n    \n    image = preprocess(image)\n    image = image/255\n    pred = model.predict(image.reshape(1, 256, 64, 1))\n    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n                                       greedy=True)[0][0])\n    plt.title(num_to_label(decoded[0]), fontsize=12)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:41:02.942424Z","iopub.execute_input":"2021-08-04T14:41:02.942778Z","iopub.status.idle":"2021-08-04T14:41:03.449880Z","shell.execute_reply.started":"2021-08-04T14:41:02.942744Z","shell.execute_reply":"2021-08-04T14:41:03.449028Z"},"trusted":true},"execution_count":67,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 72x72 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAEYAAAA6CAYAAAANzi8+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAJHUlEQVRoge2Z/W9T1xnHP8dvIZfEcbCd0ODaSRxRSEhS1gANSJnSKlVZJ7Ur6lo6jU7ab/0rqr39tklbRSWQWvbKxlRRDUSlltKpFSS4JRCIFRLMmhCS2MaN4zh+C/a9Zz+UeM7LDXUgXVX5Ix3J997z8pyvn3Oe594jpJSUWI7h/23At5WSMDqUhNGhJIwOJWF0KAmjQ0kYHR6qMEKIMSHEXSGEY8n9ASGEFELUCyH+eO/37oLnTUKIZQnVvbo5IUTdkvtvCCGyQohEQYk9zLmsh8eMAgcXLoQQrUD5kjpR4FerdSKE2AgcAGaBn6xQ5YSUsqKg2B7M7MWshzB/AQ4VXL8G/HlJnT8BbUKI76/SzwEgBvziXh/fKOshzEXAKoTYLoQwAi8Df11SJwX8Bvj1Kv28Bvwd+AewTQjxvXWwVZf12nwXvKYHGAYmV6hzBHALIfYvfSCEcAPdwHEpZRg4x3Kv+bEQIlZQ/v0wJ7CewrwK/IzlywgAKeU88Mt7RSx5/FPgupRy4N7134BXhRDmgjr/lFLaCkr3w5zAuggjpbzFV5vwD4CTq1Q9BlQBP1py/xDQKIQICSFCwO8AB7DMu9YL0zr2/XOgWkqZFEKsOI6UMieEeAP4w8I9IUQn4AV2ApGC6r/lq+V0at0sLmDdEjwp5X+klJe+RtW/A8GC69eAf0kpB6WUoYUC/B74oRBi0716Ly/JYxJCiJqHZb8ofahamdIrgQ4lYXQoCaNDSRgdSsLocL885rsespZm3HlKHqNDSRgdSsLoUBJGh5IwOqzp7VpVVbLZLJqmYTKZMJvNCKG7wSOl5O7du6iqisFgwGKxYDAU/58EAgH8fj/19fW0tLRgsVjWYv7XYk3CjIyMcP78eWKxGG1tbezZswebzaYrTjgcpre3lxs3blBTU0N3dzcNDQ1FjSml5Nq1axw7doxnnnkGr9f77RNmYGCAd955h5s3b7Jv3z4sFgudnZ2Uly89DIBcLsfg4CBHjx7l0qVLbN++nS1btuB2uzEajUWNm0wmCYfDzM7OoqrqWkz/2qxpj0kkEszPz1NZWYnP56O3t5dYbOVjnUgkQm9vL5FIBJvNRiKRIJlMsvRzh5QSTdNQVRVN05Y9B/LLTwixoncutFdVdcX2xbDmL3iKotDQ0EA4HCYQCDAxMUFtbe2ivUNVVcbGxhgeHsbj8QBw+/ZtpJR5w7PZLIlEgi+//JLZ2dn8vmW329m8eTNlZWX3tUXTNOLxOBMTE6TTaQCqqqqora2loqKiaM+EBxDGbDbj9XrxeDxcvXoVv99PW1vbookkk0kGBweZnp6ms7OTaDRKMPi/j3VSSm7fvs2FCxf45JNPuHnzJolEgsrKSjo6OnjllVdoaWlhw4YNunbkcjkikQhnz57lzJkzTE9PYzQacbvdPPvss3R2dlJXV6fbXo81h2uDwYDD4aCrqwuLxcKVK1eYnp7Oe4KmaQSDQS5fvozVamXnzp1UVFSgadqiSfX29vLee+8xNzfHzp076erqorq6mlOnTnH06FECgYDustA0jfHxcd5++23efPNNjEYjTz/9NE899RSzs7McPnyYd999l0QiUfT81uQxC0vBYDDQ2NiIy+VieHiY69ev43Q6MZvNpFIp/H4/o6Oj7N69G6/Xy2effbaoH6PRSGtrKw6HA7fbjc1mw2AwMDY2xltvvcXQ0BCBQIDm5uYVw3sqleLChQt88MEH7Nmzh0OHDtHQ0IAQgt27d3PkyBHOnz9Pd3c3zc3NRS2pB07w7HY7O3bsIJ1O4/P5mJubQ0pJLBajv78fVVXZsWMHNtvyo2WDwcBjjz1GV1cXW7duxWq1YjabsdvtNDU1kUqliEQiuhEomUwSCATIZDK0t7fjdDqBr/44h8NBTU0NwWCQqampoqPYAx+fKIpCe3s7H3/8MX19fbzwwgsoisLY2BjXrl3D7XbT3Nysm3OYTCZmZmb44osvGBoa4tatW8TjcQYGBojFYmQymUXLr5C5uTnu3LlDIpGgr6+PycnJvFek02lGRkZIpVJEo9FvRpjCUGkymaivr2fbtm18+OGH+P1+FEWhv7+fiYkJnnvuOdxuN5lMZlk/qqri9/s5ceIEPp8PRVHQNI1cLkcwGLxvdpxOp4nH48TjcUZGRpiamlrUJpvN0tLSQl1dXdGRac17TCF2u52Ojg7OnTvHp59+islk4vLly9TV1dHa2oqiKMuEkVIyNzfH+++/j8/no7W1lZdeegm73U46neb06dOcPHly1XzEYrGwceNGGhoaeP3112lra1vmmRaLBYfDUXSW/MBLSQiBoihs3bqVLVu24PP5iEajXL9+nRdffJFt27ZhMi0fZmEfGhoaQlEUnn/+eXbt2oXZbGZmZobKykrdRG4BRVHYtGkT2WwWAJfLhdVqzbdZSPZWGv9+PJS3a6PRiMvloquri2AwyJkzZ1AUhb1791JVVbXq5AAymQzRaJRYLMbU1BT9/f189NFHzM/Pr9rObrfz+OOPYzAYOH36NBcvXmR8fJxQKMStW7e4cuUKfX19RKPRojPhNXnMwj6Qy+XyA1qtVvbu3cuJEydIJpM0NzfT3t6+6N8qbCOEyC/BU6dOcfz4ca5evUo2m2V8fJwbN26Qy+UWbZoLqf7CK8OGDRvo6Oigp6eHs2fPcvjwYVwuF+Xl5aRSKTKZDPX19Tz66KPY7fb7/kEPLIzL5eKJJ57A4/HkJ26xWGhsbOTAgQOMjo7S09NDdXV13hiLxUJTUxPxeJza2lqMRiMVFRXs378fo9FIX18fgUCAsrIyvF4vTz75JH6/H4/Hk99QH3nkEXbt2kVjYyNmsxmDwYDb7ebgwYN4PB4+//xzwuEwmqZRXl6O1+tl3759OByOokSB+59dr/gwEokwMzOD1WqlpqYmb7iqqty5c4dkMonT6aSqqirfJpfLEQqFSCQSbN68OZ/XaJrG7Owsk5OTZDIZysrKcDqdlJeXEwqFqK6uxul0IoQgGo0SDoex2WzU1NQsijSZTIZQKEQsFkNV1Xw/DodjtYikq9aahPkOUTo+KZaSMDqUhNGhJIwO9wvXxcW47xAlj9GhJIwOJWF0KAmjQ0kYHUrC6PBftCXC613hgyYAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"\nplt.figure(figsize=(3, 1))\nfor i in range(1):\n    ax = plt.subplot(1, 1, i+1)\n    img_dir = \"/kaggle/input/test234567575/test2.PNG\"\n    image = cv2.imread(img_dir, cv2.IMREAD_GRAYSCALE)\n    plt.imshow(image, cmap='gray')\n    \n    image = preprocess(image)\n    image = image/255\n    pred = model.predict(image.reshape(1, 256, 64, 1))\n    decoded = K.get_value(K.ctc_decode(pred, input_length=np.ones(pred.shape[0])*pred.shape[1], \n                                       greedy=True)[0][0])\n    plt.title(num_to_label(decoded[0]), fontsize=12)\n    plt.axis('off')","metadata":{"execution":{"iopub.status.busy":"2021-08-04T14:51:26.389517Z","iopub.execute_input":"2021-08-04T14:51:26.389842Z","iopub.status.idle":"2021-08-04T14:51:26.496762Z","shell.execute_reply.started":"2021-08-04T14:51:26.389814Z","shell.execute_reply":"2021-08-04T14:51:26.495945Z"},"trusted":true},"execution_count":70,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 216x72 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}